<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2020-05-22 Fri 10:58 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Change Detection Using Machine Learning</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Braxton" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2019 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">Change Detection Using Machine Learning</h1>
<p>
-<b>- mode: org -</b>-
</p>


<div id="outline-container-org9fe6a0a" class="outline-2">
<h2 id="org9fe6a0a">Useful Links</h2>
<div class="outline-text-2" id="text-org9fe6a0a">
</div>
<div id="outline-container-org0f165eb" class="outline-3">
<h3 id="org0f165eb"><a href="https://github.com/wenhwu/awesome-remote-sensing-change-detection">List of datasets, codes, papers and constests related to remote sensing change detection</a></h3>
</div>
</div>

<div id="outline-container-org8b4d1a5" class="outline-2">
<h2 id="org8b4d1a5">ML Methods to become familiar with</h2>
<div class="outline-text-2" id="text-org8b4d1a5">
</div>
<div id="outline-container-org71d11d5" class="outline-3">
<h3 id="org71d11d5"><span class="todo TODO">TODO</span> LSTM blocks</h3>
</div>
</div>

<div id="outline-container-orge04e022" class="outline-2">
<h2 id="orge04e022">April 21, 2020</h2>
<div class="outline-text-2" id="text-orge04e022">
</div>
<div id="outline-container-org6cc743f" class="outline-3">
<h3 id="org6cc743f">Initial Questions</h3>
<div class="outline-text-3" id="text-org6cc743f">
<div class="INFO">
<p>
&bull; What is QI data and how can it help us?
</p>

<p>
&bull; How will having mulitspectral images assist in change detection?
</p>

<p>
&bull; Am I stupid for not knowing where the x8 comes from in 10980x10980x8 that defines a certian .jp2 file?
</p>

</div>
</div>
</div>

<div id="outline-container-org2bf79fb" class="outline-3">
<h3 id="org2bf79fb">Done today</h3>
<div class="outline-text-3" id="text-org2bf79fb">
<div class="info">
<p>
&bull; Created GitHub
</p>

<p>
&bull; Created progress/prep document
</p>

<p>
&bull; Finished intern orientation and necessary documents.
</p>

<p>
&bull; Created an account with USGS and downloaded some data
</p>

<p>
&bull; Read through some examples of U-nets in colab
</p>

</div>
</div>
</div>
<div id="outline-container-org4141682" class="outline-3">
<h3 id="org4141682">Understanding The Data</h3>
<div class="outline-text-3" id="text-org4141682">
</div>
<div id="outline-container-org53d5861" class="outline-4">
<h4 id="org53d5861">Sentinal-2 data</h4>
<div class="outline-text-4" id="text-org53d5861">
<div class="INFO">
<p>
&bull; 650MB file size.
</p>

<p>
&bull; One file for each of the 13 spectral bands plus metadata .jp2 filetype
</p>

<p>
&bull; 10980x10980x8
</p>

<p>
&bull; Use QI data to Georeference the data?
</p>

<p>
&bull; Maybe the GeoTIFF file could help.
</p>

</div>
</div>
</div>
</div>
<div id="outline-container-org5f35965" class="outline-3">
<h3 id="org5f35965">TODO</h3>
<div class="outline-text-3" id="text-org5f35965">
<div class="note">
<p>
&bull; Add Brain and Ryan as contributers
</p>

<p>
&bull; Hopefully start using confluence and get VDI set up.
</p>

<p>
&bull; More research into what has been done regarding U-nets with complex images
</p>

<p>
&bull; More research into Change Detection Dataset
</p>

<p>
&bull; Get more of an idea as to what has already been done regarding this project
</p>

</div>
</div>
</div>
</div>


<div id="outline-container-orgeb48cab" class="outline-2">
<h2 id="orgeb48cab">April 22, 2020</h2>
<div class="outline-text-2" id="text-orgeb48cab">
</div>
<div id="outline-container-orge1b5271" class="outline-3">
<h3 id="orge1b5271">Questions</h3>
<div class="outline-text-3" id="text-orge1b5271">
<div class="info">
<p>
&bull; CUDA issues
</p>

</div>
</div>
</div>
<div id="outline-container-orgef47047" class="outline-3">
<h3 id="orgef47047">Discussion</h3>
<div class="outline-text-3" id="text-orgef47047">
<div class="info">
<p>
&bull; Found GitHub <a href="https://github.com/mpapadomanolaki/UNetLSTM">code</a> that detects urban changes in sentinel-2 data (pytorch) (Uses GPU through CUDA platform)
</p>

</div>
</div>
</div>
</div>

<div id="outline-container-org1b6e743" class="outline-2">
<h2 id="org1b6e743">April 23, 2020</h2>
<div class="outline-text-2" id="text-org1b6e743">
</div>
<div id="outline-container-org39ba0ae" class="outline-3">
<h3 id="org39ba0ae">Unet by zhixuhao</h3>
<div class="outline-text-3" id="text-org39ba0ae">
<div class="info">
<p>
&bull; Fully Implemetned into colab using google's GPU
<a href="https://colab.research.google.com/drive/13xPzNxzljETvH4ZwZE9nMV1bWY4G8iBd">link to google colab</a>- You might not have permissions to this
</p>

</div>
</div>
<div id="outline-container-org84a4b6f" class="outline-4">
<h4 id="org84a4b6f">Results</h4>
<div class="outline-text-4" id="text-org84a4b6f">
<div class="info">
<p>
&bull; GPU train time: 996 seconds
</p>

<p>
&bull; CPU train time: Way too long
</p>

<p>
&bull; TPU train time: each epoch &asymp; 7 hours
</p>

<p>
TODO &bull; Find details of data for Brian
&bull; Te best answer Brian's question, we are taining 30 images where our
steps _per _epoch = 2000
</p>



<div id="orgeba2875" class="figure">
<p><img src="./0.png" alt="0.png" width="200px" />
</p>
<p><span class="figure-number">Figure 1: </span>Actual 0</p>
</div>


<div id="orgefac191" class="figure">
<p><img src="./0_predict.png" alt="0_predict.png" width="200px" />
</p>
<p><span class="figure-number">Figure 2: </span>Predicted 0</p>
</div>


<div id="org6cd97d6" class="figure">
<p><img src="./0.png" alt="0.png" width="200px" />
</p>
<p><span class="figure-number">Figure 3: </span>Actual 1</p>
</div>


<div id="orgc3f6b31" class="figure">
<p><img src="./0_predict.png" alt="0_predict.png" width="200px" />
</p>
<p><span class="figure-number">Figure 4: </span>Predicted 1</p>
</div>

</div>
</div>
</div>
</div>
</div>

<div id="outline-container-org01d946d" class="outline-2">
<h2 id="org01d946d">April 24, 2020</h2>
<div class="outline-text-2" id="text-org01d946d">
</div>
<div id="outline-container-org6289d5a" class="outline-3">
<h3 id="org6289d5a"><span class="todo TODO">TODO</span> Notes</h3>
<div class="outline-text-3" id="text-org6289d5a">
<div class="info">
<p>

</p>

<p>
To answer Ryan's question The two training images are pngs with size 1.2MB 785x799
the masks are also pngs of dementions 785x799 but only around 11.0kB
</p>

<p>
zhinxuhao uses images that are pngs of dementions 512x512 and size of around 215kB and labels of
same demention size 15kB.
</p>

<p>
I feel that my next step is going to be reproducing zhixuhao's u-net with the onera dataset.
The onera dataset however comes with two images for every mask. So I am going to need to disect
the code and understand what changes I need to make so that we can change this mask prediction problem
to now input two images insted of the one to make it a change detection problem. This might take a sec.
</p>

<p>
This actually is almost impossible without a large change to the architecture of the neural net. I am
now looking at the Siamese network that has a change detection architecture. Good reaserch to do would be
looking into the diffrences between VGG16 and u-net maybe it would be cool to use u-net inseted of VGG16
</p>

<p>
Also a little note here for me to check out dice metric and IOU metric.
</p>

</div>
</div>
</div>
<div id="outline-container-org5efa736" class="outline-3">
<h3 id="org5efa736">Notes about code</h3>
<div class="outline-text-3" id="text-org5efa736">
<div class="info">
<p>
&bull; In Siamese-neural-network-for-change-detection they seem to do some sort of concatination to create
one large feature map - slide 9
</p>

<p>
<a href="https://github.com/vbhavank/Siamese-neural-network-for-change-detection">Link to Siamese NN code</a>
</p>

<p>
<a href="https://sigport.org/sites/default/files/docs/Siamese_Network_RIT_Nov2018_0.pdf">Link to slideshow explaining Siamese NN</a>
</p>

<p>
&bull; I think it would be a good idea to talk about slide 8(pre-trained on ImageNet?)(why pre-train it?)
</p>

</div>
</div>
</div>
</div>

<div id="outline-container-org57aa0a9" class="outline-2">
<h2 id="org57aa0a9">April 27,2020</h2>
<div class="outline-text-2" id="text-org57aa0a9">
</div>
<div id="outline-container-orge37ce5c" class="outline-3">
<h3 id="orge37ce5c">Colab resource limits</h3>
<div class="outline-text-3" id="text-orge37ce5c">
<div class="info">
<p>
<a href="https://research.google.com/colaboratory/faq.html#resource-limits">Colab resource limits</a>
&bull; look into details about colab pro
</p>

</div>
</div>
</div>
</div>

<div id="outline-container-org2dde7d8" class="outline-2">
<h2 id="org2dde7d8">April 28, 2020</h2>
<div class="outline-text-2" id="text-org2dde7d8">
</div>
<div id="outline-container-org8013f4b" class="outline-3">
<h3 id="org8013f4b">The universal Workflow of machine learning</h3>
<div class="outline-text-3" id="text-org8013f4b">
</div>
<div id="outline-container-org4b4c4f3" class="outline-4">
<h4 id="org4b4c4f3">Defining the problem and assembling a dataset</h4>
<div class="outline-text-4" id="text-org4b4c4f3">
<div class="info">
<p>

</p>

</div>
</div>
</div>
<div id="outline-container-org51c51f6" class="outline-4">
<h4 id="org51c51f6">Choosing a measure of success</h4>
<div class="outline-text-4" id="text-org51c51f6">
<div class="info">
<p>

</p>

</div>
</div>
</div>
<div id="outline-container-org89a1477" class="outline-4">
<h4 id="org89a1477">Deciding on a evaluation protocol</h4>
<div class="outline-text-4" id="text-org89a1477">
<div class="info">
<p>

</p>

</div>
</div>
</div>
<div id="outline-container-orgdbbd7a6" class="outline-4">
<h4 id="orgdbbd7a6">Preparing your data</h4>
<div class="outline-text-4" id="text-orgdbbd7a6">
<div class="info">
<p>

</p>

</div>
</div>
</div>
<div id="outline-container-org7cada21" class="outline-4">
<h4 id="org7cada21">Developing a model that does better than  a baseline</h4>
<div class="outline-text-4" id="text-org7cada21">
<div class="info">
<p>

</p>

</div>
</div>
</div>
<div id="outline-container-org86da54d" class="outline-4">
<h4 id="org86da54d">Scaling up: developing a model that overfits</h4>
<div class="outline-text-4" id="text-org86da54d">
<div class="info">
<p>

</p>

</div>
</div>
</div>
<div id="outline-container-org0d5cd2d" class="outline-4">
<h4 id="org0d5cd2d">Regularizing your model and tuning your hyperparameters</h4>
<div class="outline-text-4" id="text-org0d5cd2d">
<div class="info">
<p>

</p>

</div>
</div>
</div>
</div>
<div id="outline-container-orgbd39b94" class="outline-3">
<h3 id="orgbd39b94">Random idea</h3>
<div class="outline-text-3" id="text-orgbd39b94">
<div class="info">
<p>
What if we did a unet for both of the images(this is assuming we had maskes for our data)
then just subracted the two masks? Would this not leave us with a mask of the changes?
</p>

</div>
</div>
</div>
</div>


<div id="outline-container-orgef0ef8c" class="outline-2">
<h2 id="orgef0ef8c">April 29, 2020</h2>
<div class="outline-text-2" id="text-orgef0ef8c">
</div>
<div id="outline-container-org24031d2" class="outline-3">
<h3 id="org24031d2">Siamese Neural Networks</h3>
<div class="outline-text-3" id="text-org24031d2">
<div class="info">
<p>
The Siamese Neural Network seems to be popular with One-Shot-Learning. It is a farely straight-forward NN that inputs
two images and runs both of them throught a CNN then flattens it and runs is through a dense nn with AF = Sigmoid.
It then calculates the abs() of the diffrence and uses that in one more Dense to classify it as two diffrent images
or the same image. I spent a few hours changing this algorithm to insted build an image out of the absolute diffrence
using a Unet architecture. This might not be possible but it is woth a try and I learned a lot in the process about U-nets and Siamese nets
<a href="https://colab.research.google.com/drive/1D2S5uOzTVreKS0yXBAVSxKfH-KjUHEf3?usp=sharing">Here is a link to this unfinished NN</a>
</p>

</div>
</div>
</div>
<div id="outline-container-org89d5367" class="outline-3">
<h3 id="org89d5367">Further Research</h3>
<div class="outline-text-3" id="text-org89d5367">
<div class="info">
<p>
&bull; Dual attentive fully convolutional siamese networks for change detection of high-resolution satellite images
&bull; I think this is what we are looking for. I will spend some time tomorrow looking over this code and paper to see
how they use the siamese network to not only find the L2 distance and create and image from the distance.
</p>

</div>
</div>
</div>
</div>


<div id="outline-container-org65dc542" class="outline-2">
<h2 id="org65dc542">May 4, 2020</h2>
<div class="outline-text-2" id="text-org65dc542">
</div>
<div id="outline-container-org5869c8c" class="outline-3">
<h3 id="org5869c8c">Onera Dataset</h3>
<div class="outline-text-3" id="text-org5869c8c">
<div class="info">
<p>
Data can be downloaded <a href="https://rcdaudt.github.io/oscd/">Here</a>
There are three zip files that you can download, Images(512MB), Train labels(137kB), and Test labels(83kB).
</p>

<p>
The Images zip file contains images from 24 different locations around the world. Each location has five files.
Three of wich I belive we are particualy interested in. two of the files are the 13 diffrent bands for the image at T<sub>1</sub>
and at T<sub>2</sub> Here is an example of a few. These are bands 1-5 of T<sub>1</sub> and T<sub>2</sub>.
</p>
<p width="200px">
<a href="./B01a.tif" width="200px">./B01a.tif</a>
</p>

<p width="200px">
<a href="./B02a.tif" width="200px">./B02a.tif</a>
</p>

<p width="200px">
<a href="./B03a.tif" width="200px">./B03a.tif</a>
</p>

<p width="200px">
<a href="./B04a.tif" width="200px">./B04a.tif</a>
</p>

<p width="200px">
<a href="./B05a.tif" width="200px">./B05a.tif</a>
</p>


<p>
As you can see, These are hardly visible. But this should hopfuly be no issue for the computer
</p>


<p>
The third file contains a png of image at T<sub>1</sub> and T<sub>2</sub> as shown
</p>


<div class="figure">
<p><img src="./img1.png" alt="img1.png" width="200px" />
</p>
</div>


<div class="figure">
<p><img src="./img2.png" alt="img2.png" width="200px" />
</p>
</div>

<p>
The other two zip files (Train Labels and Test Label) contain two iamges of the change mask both in both .tif and .png format.
</p>

<p>
These images look like this.
</p>

<p width="200px">
<a href="./abudhabi-cm.tif" width="200px">./abudhabi-cm.tif</a>
</p>

<p>
This could be a completely black image and I would not know the difference. The .tif is seen above.
</p>


<div class="figure">
<p><img src="./cm.png" alt="cm.png" width="200px" />
</p>
</div>


<p>
It is important to note that for this particular location, all imagaes are 785x799
</p>

</div>
</div>
</div>
</div>



<div id="outline-container-org51195fd" class="outline-2">
<h2 id="org51195fd">May 12, 2020</h2>
<div class="outline-text-2" id="text-org51195fd">
</div>
<div id="outline-container-org948301d" class="outline-3">
<h3 id="org948301d"><a href="https://colab.research.google.com/drive/1nvf002MOS669Pj_4NUbus-eyi0Rd3taW?usp=sharing">Here is a Link to a colab document processing the tiff images</a></h3>
</div>
</div>

<div id="outline-container-orgf48d28e" class="outline-2">
<h2 id="orgf48d28e">May 14, 2020</h2>
<div class="outline-text-2" id="text-orgf48d28e">
</div>
<div id="outline-container-orgbb954e2" class="outline-3">
<h3 id="orgbb954e2">Looking at the jp2 images provided by earthexplorer</h3>
<div class="outline-text-3" id="text-orgbb954e2">
<div class="info">
<p>
This image is showing the search capability of EarthExplorer. The blue outline is the downloadable image from Earth
Exploerer and the red box is the onera image.
</p>



<div class="figure">
<p><img src="./EEimage_AbuDhabi.png" alt="EEimage_AbuDhabi.png" width="600px" />
</p>
</div>

</div>
</div>
</div>

<div id="outline-container-org7647a3a" class="outline-3">
<h3 id="org7647a3a">Spatial Data</h3>
<div class="outline-text-3" id="text-org7647a3a">
<div class="info">
<p>
Idealy I want to take this large jp2 and crop the long lat data to leave us with the exact same image as the onera dataset
I am in the prosess of learning about spacial data and how I can crop a hp2 or geotiff image.
</p>

</div>
</div>
</div>
<div id="outline-container-org7b44c5d" class="outline-3">
<h3 id="org7b44c5d">questions</h3>
<div class="outline-text-3" id="text-org7b44c5d">
<div class="info">
<p>
(please don't feel like you need to answer my questions. I will eventually figure it out.
I just thought it would be good for you to know what questions I have at this point)
Hey Brian, are you familiar with gdal? Is there a way I can crop the jp2 image using lat and long?
I guess my main issue is I am unfamiliar with jp2 and geotiff files.
I know there is metadata in the xml file that comes with the jp2 images, but is there location data
within the jp2 or geotiff itself that can be accessed without the xml file? What exactly happens when
you convert a jp2 to a geotiff?
</p>

<p>
when I fun a dalinfo on the xml file provided it returns:
Coordinate System is `'
</p>

<p>
I believe I can crop this image usign a bounding box from gdal. I believe the function is gdalwarp.
</p>

<p>
<a href="https://gis.stackexchange.com/questions/214489/handle-jp2-sentinel-data">Handle .p2 Sentinel data</a>
</p>

</div>
</div>
</div>
</div>


<div id="outline-container-org5619a06" class="outline-2">
<h2 id="org5619a06">May 16, 2020</h2>
<div class="outline-text-2" id="text-org5619a06">
</div>
<div id="outline-container-org472613e" class="outline-3">
<h3 id="org472613e"><a href="https://colab.research.google.com/drive/1JYZpoj0ubWiZsZkE_wAxJH3YH0nUQI7K?usp=sharing">Recreating the Onera Dataset</a></h3>
</div>
</div>


<div id="outline-container-org4ca2184" class="outline-2">
<h2 id="org4ca2184">May 21, 2020 (initial lookover)</h2>
<div class="outline-text-2" id="text-org4ca2184">
</div>
<div id="outline-container-orgcdd63bb" class="outline-3">
<h3 id="orgcdd63bb">Siamese-neural-network-for-change-detection</h3>
<div class="outline-text-3" id="text-orgcdd63bb">
<div class="info">
<p>
&bull; Keras (Siamese CNN)
</p>

<p>
&bull; computaionaly generated dataset
</p>

</div>
</div>
</div>
<div id="outline-container-org43a7a17" class="outline-3">
<h3 id="org43a7a17">FCSN-for-ChangeDectection</h3>
<div class="outline-text-3" id="text-org43a7a17">
<div class="info">
<p>
&bull; Onera dataset
</p>

<p>
&bull; pytorch model (Fully Convolutional Siamese Network)
</p>

<p>
&bull; creats mini images from the pngs of the onera dataset
</p>

<p>
&bull; data prosessing provided
</p>

</div>
</div>
</div>
<div id="outline-container-orgfd118bb" class="outline-3">
<h3 id="orgfd118bb">End-to-end-CD-for-VHR-satellite</h3>
<div class="outline-text-3" id="text-orgfd118bb">
<div class="info">
<p>
&bull; 7 pairs of images with a size of 1900 X 1000
</p>

<p>
&bull; keras model (unet++)
</p>

<p>
&bull; only the model is provided, no data preprossing
</p>

</div>
</div>
</div>
<div id="outline-container-orgf0a3983" class="outline-3">
<h3 id="orgf0a3983">ChangeDetectionBaseline</h3>
<div class="outline-text-3" id="text-orgf0a3983">
<div class="info">
<p>
&bull; Keras Model(Siamese CNN)
</p>

<p>
&bull; Lots of documentation, a bit messy, I will deticate more time to this one tommorow.
</p>

</div>
</div>
</div>
<div id="outline-container-org409d782" class="outline-3">
<h3 id="org409d782">chip-segmentaion</h3>
<div class="outline-text-3" id="text-org409d782">
<div class="info">
<p>
&bull; Pytorch (RNN)
</p>

<p>
&bull; This one also has a lot of parts, It will take me a sec to go over this.
</p>

<p>
&bull; Onera dataset
</p>

</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Braxton</p>
<p class="date">Created: 2020-05-22 Fri 10:58</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
